{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural and N-Gram Language Model and for CPSC 503 Assignment 2\n",
    "### The neural model notebook is modified from Yunjey Choi's Github repository - pytorch-tutorial.\n",
    "### pytorch-tutorial/tutorials/02-intermediate/language_model/\n",
    "### https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model\n",
    "\n",
    "### The N-gram model notebook is from Josh Loehr's Github repository - ngram-language-model.\n",
    "### https://github.com/joshualoehr/ngram-language-model\n",
    "\n",
    "### ========================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First of the first, let's load a number of dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are two classes needed for the data loading and formating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    # < MISSING CLASS DESCRIPTION >\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def return_dict(self):\n",
    "        return self.idx2word\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    # < MISSING CLASS DESCRIPTION >\n",
    "    def __init__(self):\n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "    def get_data(self, path, n_gram=2):\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0;\n",
    "            sample_list = []\n",
    "            for line in f:\n",
    "                words = ['<start>'] * n_gram + line.split() # < MISSING COMMENT >\n",
    "                tokens += len(words)\n",
    "                sample_list.append(words)\n",
    "                for word in words: \n",
    "                    self.dictionary.add_word(word)  \n",
    "\n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        ids_list = [[0]*len(s) for s in sample_list if len(s) > n_gram] \n",
    "        with open(path, 'r') as f:\n",
    "            sample_num = 0\n",
    "            for line in f:\n",
    "                token = 0\n",
    "                words = ['<start>'] * n_gram + line.split()\n",
    "                if len(words) > n_gram:\n",
    "                    for word in words:\n",
    "                        ids_list[sample_num][token] = self.dictionary.word2idx[word]\n",
    "                        token += 1\n",
    "                    sample_num += 1\n",
    "\n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        for n in range(len(ids_list)):\n",
    "            flat_ids = ids_list[n]\n",
    "            ids_list[n] = torch.LongTensor([flat_ids[i:i+n_gram+1] for i in range(len(flat_ids)-n_gram)])\n",
    "        return ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram = 3\n",
    "\n",
    "embed_size = 128\n",
    "intermediate_size = 1024\n",
    "num_epochs = 10\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the \"Penn Treebank\" dataset and split it into train/dev/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "ids = corpus.get_data('data/train_mini.txt', n_gram-1)\n",
    "train_ids = ids[:-200]\n",
    "dev_ids = ids[-200:-100]\n",
    "test_ids = ids[-100:]\n",
    "vocab_size = len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class of n-gram language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLM(object):\n",
    "    def __init__(self, vocab_size, x_n, x_m, laplace=1):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.laplace = laplace\n",
    "        \n",
    "        # Dictionaries for tracking the count of n-grams\n",
    "        self.n_gram_count = self.count_ngrams(x_n)\n",
    "        self.m_gram_count = self.count_ngrams(x_m)\n",
    "    \n",
    "    def count_ngrams(self, x):\n",
    "        \"\"\"\n",
    "        Populate the dictionary with the number of occurrences of each n-gram\n",
    "        \"\"\"\n",
    "        count_list = defaultdict(int)\n",
    "        for example in x:\n",
    "            for n_gram in example.tolist():\n",
    "                count_list[tuple(n_gram)] += 1 \n",
    "        return count_list\n",
    "    \n",
    "    def compute_mle(self, n_gram):\n",
    "        \"\"\"\n",
    "        Compute the MLE of P(w_n|w_{nâˆ’1}, ...) with add-one Laplacian smoothing \n",
    "        \"\"\"\n",
    "        n_count = self.n_gram_count[n_gram]\n",
    "        m_gram = n_gram[:-1]\n",
    "        m_count = self.m_gram_count[m_gram]\n",
    "        prob = (n_count + self.laplace) / (m_count + self.laplace * self.vocab_size) \n",
    "        return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the n-gram model based on MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average training perplexity for N-gram LM: 1464.8837207362549\n"
     ]
    }
   ],
   "source": [
    "# Populate the dictionaries with counts from training corpus\n",
    "m_gram = n_gram - 1\n",
    "m_gram_train_ids = corpus.get_data('data/train_mini.txt', n_gram-2)[:-200]\n",
    "n_gram_train_ids = train_ids\n",
    "\n",
    "model = NGramLM(vocab_size, n_gram_train_ids, m_gram_train_ids)\n",
    "\n",
    "# Compute average perplexity on training set\n",
    "train_ppl = 0\n",
    "for i in range(0, len(train_ids)):\n",
    "\n",
    "    probabilities = list(map(lambda x: model.compute_mle(tuple(x)), train_ids[i].tolist()))\n",
    "    perplexity = np.exp(sum(-np.log(probabilities)) / len(train_ids[i]))\n",
    "    train_ppl += perplexity\n",
    "    \n",
    "print('The average training perplexity for N-gram LM: '+str(train_ppl/len(train_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for test sample 0 : 3117.1487062216083\n",
      "Perplexity for test sample 1 : 2889.9450889166437\n",
      "Perplexity for test sample 2 : 2064.8644143110246\n",
      "Perplexity for test sample 3 : 3579.142800151963\n",
      "Perplexity for test sample 4 : 3192.5345501363786\n",
      "Perplexity for test sample 5 : 2236.3169582936957\n",
      "Perplexity for test sample 6 : 3181.4940906216416\n",
      "Perplexity for test sample 7 : 3468.124739622231\n",
      "Perplexity for test sample 8 : 3152.878827231253\n",
      "Perplexity for test sample 9 : 3579.0000000000005\n",
      "Perplexity for test sample 10 : 3217.8170238617386\n",
      "Perplexity for test sample 11 : 2855.8295692385764\n",
      "Perplexity for test sample 12 : 2809.6022165773124\n",
      "Perplexity for test sample 13 : 2510.8634250307455\n",
      "Perplexity for test sample 14 : 1960.5092731715915\n",
      "Perplexity for test sample 15 : 2608.9912879228987\n",
      "Perplexity for test sample 16 : 2675.1672745072965\n",
      "Perplexity for test sample 17 : 3118.549302583625\n",
      "Perplexity for test sample 18 : 2513.006687888638\n",
      "Perplexity for test sample 19 : 2752.323920225562\n",
      "Perplexity for test sample 20 : 2893.6380150892314\n",
      "Perplexity for test sample 21 : 2790.622779226043\n",
      "Perplexity for test sample 22 : 2798.4943896999325\n",
      "Perplexity for test sample 23 : 1897.631422417479\n",
      "Perplexity for test sample 24 : 2706.4547653872555\n",
      "Perplexity for test sample 25 : 2713.2199270866568\n",
      "Perplexity for test sample 26 : 3579.0000000000005\n",
      "Perplexity for test sample 27 : 3060.5808295277284\n",
      "Perplexity for test sample 28 : 3287.108868696145\n",
      "Perplexity for test sample 29 : 2445.573485274195\n",
      "Perplexity for test sample 30 : 3349.7511772785674\n",
      "Perplexity for test sample 31 : 2938.768565242741\n",
      "Perplexity for test sample 32 : 3578.999999999994\n",
      "Perplexity for test sample 33 : 3581.9444634493293\n",
      "Perplexity for test sample 34 : 2856.5222130546754\n",
      "Perplexity for test sample 35 : 3097.926783213742\n",
      "Perplexity for test sample 36 : 2871.464035850652\n",
      "Perplexity for test sample 37 : 3025.8655245165633\n",
      "Perplexity for test sample 38 : 2566.677954960185\n",
      "Perplexity for test sample 39 : 3579.0000000000005\n",
      "Perplexity for test sample 40 : 3585.0705354507513\n",
      "Perplexity for test sample 41 : 3232.504637398806\n",
      "Perplexity for test sample 42 : 2013.3536887478394\n",
      "Perplexity for test sample 43 : 2322.2336575417467\n",
      "Perplexity for test sample 44 : 3587.966249794783\n",
      "Perplexity for test sample 45 : 2854.536488287352\n",
      "Perplexity for test sample 46 : 2867.574805427605\n",
      "Perplexity for test sample 47 : 2273.037374213671\n",
      "Perplexity for test sample 48 : 2824.7895239982613\n",
      "Perplexity for test sample 49 : 2869.0745024943326\n",
      "Perplexity for test sample 50 : 3579.4998952562682\n",
      "Perplexity for test sample 51 : 2804.488598094219\n",
      "Perplexity for test sample 52 : 3267.2774207666075\n",
      "Perplexity for test sample 53 : 3480.824808766358\n",
      "Perplexity for test sample 54 : 3469.6228010886325\n",
      "Perplexity for test sample 55 : 2183.3223050965707\n",
      "Perplexity for test sample 56 : 2608.0068650692106\n",
      "Perplexity for test sample 57 : 3581.364223941898\n",
      "Perplexity for test sample 58 : 2559.4861721397197\n",
      "Perplexity for test sample 59 : 3290.3128150214784\n",
      "Perplexity for test sample 60 : 2905.390358004871\n",
      "Perplexity for test sample 61 : 3196.1188187183684\n",
      "Perplexity for test sample 62 : 2748.832341928573\n",
      "Perplexity for test sample 63 : 3413.0115681885613\n",
      "Perplexity for test sample 64 : 2064.992555335434\n",
      "Perplexity for test sample 65 : 3350.7906806674227\n",
      "Perplexity for test sample 66 : 3191.0337477561948\n",
      "Perplexity for test sample 67 : 3036.916652953107\n",
      "Perplexity for test sample 68 : 2369.295284602006\n",
      "Perplexity for test sample 69 : 2593.707286365456\n",
      "Perplexity for test sample 70 : 2471.705846978703\n",
      "Perplexity for test sample 71 : 2001.912030752749\n",
      "Perplexity for test sample 72 : 3579.599659519925\n",
      "Perplexity for test sample 73 : 2449.211624089206\n",
      "Perplexity for test sample 74 : 2966.221806317952\n",
      "Perplexity for test sample 75 : 2719.111229175511\n",
      "Perplexity for test sample 76 : 2566.763000167782\n",
      "Perplexity for test sample 77 : 2880.9266343979148\n",
      "Perplexity for test sample 78 : 2727.080435309649\n",
      "Perplexity for test sample 79 : 1763.7976488254656\n",
      "Perplexity for test sample 80 : 2700.603938515761\n",
      "Perplexity for test sample 81 : 3579.4704877294203\n",
      "Perplexity for test sample 82 : 2551.675381157798\n",
      "Perplexity for test sample 83 : 3579.214202364558\n",
      "Perplexity for test sample 84 : 3321.245333969791\n",
      "Perplexity for test sample 85 : 3579.9994670745414\n",
      "Perplexity for test sample 86 : 3579.0000000000005\n",
      "Perplexity for test sample 87 : 2195.40137041458\n",
      "Perplexity for test sample 88 : 3579.4998952562682\n",
      "Perplexity for test sample 89 : 2328.8560446721754\n",
      "Perplexity for test sample 90 : 3579.0000000000005\n",
      "Perplexity for test sample 91 : 2404.311680534953\n",
      "Perplexity for test sample 92 : 2537.2931516900594\n",
      "Perplexity for test sample 93 : 1829.8134023330947\n",
      "Perplexity for test sample 94 : 1505.4035743070874\n",
      "Perplexity for test sample 95 : 3153.769221609681\n",
      "Perplexity for test sample 96 : 1936.3359142915428\n",
      "Perplexity for test sample 97 : 3287.1508039882024\n",
      "Perplexity for test sample 98 : 3003.444204723821\n",
      "Perplexity for test sample 99 : 3580.2892121803284\n",
      "The average testing perplexity for N-gram LM: 2891.658992219502\n"
     ]
    }
   ],
   "source": [
    "# Compute average perplexity on training set\n",
    "test_ppl = 0\n",
    "for i in range(0, len(test_ids)):\n",
    "\n",
    "    probabilities = list(map(lambda x: model.compute_mle(tuple(x)), test_ids[i].tolist()))\n",
    "    perplexity = np.exp(sum(-np.log(probabilities)) / len(test_ids[i]))\n",
    "    print('Perplexity for test sample '+str(i)+' :', perplexity)\n",
    "    test_ppl += perplexity\n",
    "    \n",
    "print('The average testing perplexity for N-gram LM: '+str(test_ppl/len(test_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class of neural language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, intermediate_size, n_gram):\n",
    "        super(LM, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.intermediate = nn.Linear(n_gram * embed_size, intermediate_size)\n",
    "        self.linear = nn.Linear(intermediate_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x) # < MISSING COMMENT >\n",
    "        conc_emb = x.view(x.size(0), x.size(1)*x.size(2))\n",
    "        #conc_emb = torch.cat([x[:,0,:], x[:,1,:]],1)\n",
    "        intermediate_output = self.intermediate(conc_emb) # < MISSING COMMENT >\n",
    "        final_out = self.linear(intermediate_output) # < MISSING COMMENT >\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LM(vocab_size, embed_size, intermediate_size, n_gram-1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 7.4975, Perplexity: 4435.34\n",
      "Epoch [2/10], Loss: 5.2731, Perplexity: 46597.55\n",
      "Epoch [3/10], Loss: 4.7165, Perplexity: 151783.69\n",
      "Epoch [4/10], Loss: 4.3831, Perplexity: 504945.50\n",
      "Epoch [5/10], Loss: 4.2320, Perplexity: 1279958.53\n",
      "Epoch [6/10], Loss: 4.0733, Perplexity: 3732354.98\n",
      "Epoch [7/10], Loss: 3.9003, Perplexity: 6607131.58\n",
      "Epoch [8/10], Loss: 3.7443, Perplexity: 20519255.33\n",
      "Epoch [9/10], Loss: 3.6646, Perplexity: 44540035.69\n",
      "Epoch [10/10], Loss: 3.5143, Perplexity: 61763915.74\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    avg_ppl = 0; avg_loss = 0;\n",
    "    for i in range(0, len(train_ids)):\n",
    "        inputs = train_ids[i][:, 0:n_gram-1].to(device)\n",
    "        targets = train_ids[i][:, n_gram-1:].to(device)\n",
    "        \n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.reshape(-1))\n",
    "        avg_loss += loss.item();\n",
    "        \n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "    for i in range(0, len(dev_ids)):\n",
    "        dev_inputs = dev_ids[i][:, 0:n_gram-1].to(device)\n",
    "        dev_targets = dev_ids[i][:, n_gram-1:].to(device)\n",
    "        dev_outputs = model(dev_inputs)\n",
    "        ce = criterion(dev_outputs, dev_targets.reshape(-1))\n",
    "        avg_ppl += np.exp(ce.item());\n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
    "        .format(epoch + 1, num_epochs, avg_loss/len(train_ids), avg_ppl/len(dev_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for test sample 0 : 43991473.02316608\n",
      "Perplexity for test sample 1 : 38956968.219748355\n",
      "Perplexity for test sample 2 : 432663714.7798215\n",
      "Perplexity for test sample 3 : 2278079121.956286\n",
      "Perplexity for test sample 4 : 3461183.9717070693\n",
      "Perplexity for test sample 5 : 35432045.63429264\n",
      "Perplexity for test sample 6 : 327742.8383638747\n",
      "Perplexity for test sample 7 : 706207.7372765793\n",
      "Perplexity for test sample 8 : 66998.13633510543\n",
      "Perplexity for test sample 9 : 86565921.38277905\n",
      "Perplexity for test sample 10 : 21023245.193479586\n",
      "Perplexity for test sample 11 : 199948.54056460116\n",
      "Perplexity for test sample 12 : 258972.59883020335\n",
      "Perplexity for test sample 13 : 1483864.2984453\n",
      "Perplexity for test sample 14 : 17368948.932059865\n",
      "Perplexity for test sample 15 : 6719689.085955047\n",
      "Perplexity for test sample 16 : 2857813.0067902347\n",
      "Perplexity for test sample 17 : 449770.9792981786\n",
      "Perplexity for test sample 18 : 27700551.774743408\n",
      "Perplexity for test sample 19 : 226362.9626812696\n",
      "Perplexity for test sample 20 : 3431636.2449909234\n",
      "Perplexity for test sample 21 : 14589315.713118332\n",
      "Perplexity for test sample 22 : 5250701.185295131\n",
      "Perplexity for test sample 23 : 443119.824712558\n",
      "Perplexity for test sample 24 : 228320.9634147234\n",
      "Perplexity for test sample 25 : 3240284.9675649637\n",
      "Perplexity for test sample 26 : 1433848178.5291789\n",
      "Perplexity for test sample 27 : 2330453.425980452\n",
      "Perplexity for test sample 28 : 46124392.674332194\n",
      "Perplexity for test sample 29 : 1648549582.534472\n",
      "Perplexity for test sample 30 : 751251.8241127712\n",
      "Perplexity for test sample 31 : 3263043.323418162\n",
      "Perplexity for test sample 32 : 1834077159.3115413\n",
      "Perplexity for test sample 33 : 23850054.445005383\n",
      "Perplexity for test sample 34 : 578996.959643103\n",
      "Perplexity for test sample 35 : 40026129.2387771\n",
      "Perplexity for test sample 36 : 102370.8134404255\n",
      "Perplexity for test sample 37 : 581617.9727961078\n",
      "Perplexity for test sample 38 : 84767.59783564987\n",
      "Perplexity for test sample 39 : 1242116417.6079855\n",
      "Perplexity for test sample 40 : 159601592.84221038\n",
      "Perplexity for test sample 41 : 8309895.979389446\n",
      "Perplexity for test sample 42 : 1478867.4397427016\n",
      "Perplexity for test sample 43 : 814659.1885661414\n",
      "Perplexity for test sample 44 : 274479.1804028427\n",
      "Perplexity for test sample 45 : 2258233.8298854963\n",
      "Perplexity for test sample 46 : 1025956.5744285336\n",
      "Perplexity for test sample 47 : 441630836.06720865\n",
      "Perplexity for test sample 48 : 630356.6816753959\n",
      "Perplexity for test sample 49 : 1767071.6325378097\n",
      "Perplexity for test sample 50 : 7915463.760289021\n",
      "Perplexity for test sample 51 : 774579.6389963801\n",
      "Perplexity for test sample 52 : 16179916.53472316\n",
      "Perplexity for test sample 53 : 1222823.5013106407\n",
      "Perplexity for test sample 54 : 263994.2581463506\n",
      "Perplexity for test sample 55 : 6327.610258035301\n",
      "Perplexity for test sample 56 : 3904547.115588724\n",
      "Perplexity for test sample 57 : 5606489.850980719\n",
      "Perplexity for test sample 58 : 196403.08550129057\n",
      "Perplexity for test sample 59 : 8512989.481189212\n",
      "Perplexity for test sample 60 : 319501.01325828425\n",
      "Perplexity for test sample 61 : 4685277.767095155\n",
      "Perplexity for test sample 62 : 773944.620271786\n",
      "Perplexity for test sample 63 : 3161947.3524864693\n",
      "Perplexity for test sample 64 : 150559410.23490763\n",
      "Perplexity for test sample 65 : 65544852.631656304\n",
      "Perplexity for test sample 66 : 2036314.951754617\n",
      "Perplexity for test sample 67 : 2737524760.0264316\n",
      "Perplexity for test sample 68 : 1686878.5215026555\n",
      "Perplexity for test sample 69 : 5468833.832007567\n",
      "Perplexity for test sample 70 : 48146.57631160215\n",
      "Perplexity for test sample 71 : 13069574.121118672\n",
      "Perplexity for test sample 72 : 27601716.458724104\n",
      "Perplexity for test sample 73 : 589978.1865213349\n",
      "Perplexity for test sample 74 : 176114.5380631719\n",
      "Perplexity for test sample 75 : 3096498.9536238853\n",
      "Perplexity for test sample 76 : 295324.761832792\n",
      "Perplexity for test sample 77 : 81353.76749187674\n",
      "Perplexity for test sample 78 : 63763.96249425525\n",
      "Perplexity for test sample 79 : 13904.085169453221\n",
      "Perplexity for test sample 80 : 296961.97146181035\n",
      "Perplexity for test sample 81 : 13102120.99692051\n",
      "Perplexity for test sample 82 : 1602798.8862891947\n",
      "Perplexity for test sample 83 : 505718402.1304211\n",
      "Perplexity for test sample 84 : 562248.5909396943\n",
      "Perplexity for test sample 85 : 15509642.78569421\n",
      "Perplexity for test sample 86 : 8920617.533936923\n",
      "Perplexity for test sample 87 : 2149077.5039815377\n",
      "Perplexity for test sample 88 : 7915463.760289021\n",
      "Perplexity for test sample 89 : 34904153.0543266\n",
      "Perplexity for test sample 90 : 16732.530771787115\n",
      "Perplexity for test sample 91 : 156064.69820103343\n",
      "Perplexity for test sample 92 : 100941.45273378672\n",
      "Perplexity for test sample 93 : 41438.61680961644\n",
      "Perplexity for test sample 94 : 11088.65494704322\n",
      "Perplexity for test sample 95 : 457565.440945576\n",
      "Perplexity for test sample 96 : 1404033.2461010362\n",
      "Perplexity for test sample 97 : 31001.745314451\n",
      "Perplexity for test sample 98 : 1028205.5073887911\n",
      "Perplexity for test sample 99 : 39133095.355210245\n",
      "The average testing perplexity for neural LM: 136142435.7528868\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model.ckpt')\n",
    "model.eval()\n",
    "test_ppl = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_ids)):\n",
    "        inputs = test_ids[i][:, 0:n_gram-1].to(device)\n",
    "        gold = test_ids[i][:, n_gram-1:].to(device)\n",
    "        output = model(inputs)\n",
    "        cross_entropy = criterion(output, gold.reshape(-1)).item()\n",
    "        print('Perplexity for test sample '+str(i)+' :', np.exp(cross_entropy))\n",
    "        test_ppl += np.exp(cross_entropy)\n",
    "    print('The average testing perplexity for neural LM: '+str(test_ppl/len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
